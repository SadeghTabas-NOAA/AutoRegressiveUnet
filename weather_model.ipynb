{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import os\n",
    "import random\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net model\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder1 = self.conv_block(in_channels, 64)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(256, 512)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder1 = self.upconv_block(512, 256)\n",
    "        self.decoder2 = self.upconv_block(256, 128)\n",
    "        self.decoder3 = self.upconv_block(128, 64)\n",
    "        \n",
    "        # Output layer\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "    \n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),  # padding=1 to preserve dimensions\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),  # padding=1 to preserve dimensions\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def upconv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ReLU(inplace=True),\n",
    "            self.conv_block(out_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(F.max_pool2d(enc1, 2))\n",
    "        enc3 = self.encoder3(F.max_pool2d(enc2, 2))\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(F.max_pool2d(enc3, 2))\n",
    "        \n",
    "        # Decoder\n",
    "        dec1 = self.decoder1(bottleneck)\n",
    "        dec2 = self.decoder2(dec1)\n",
    "        dec3 = self.decoder3(dec2)\n",
    "        \n",
    "        # Output\n",
    "        out = self.out_conv(dec3)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid U-Net with Auto-regressive Training\n",
    "class HybridUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, lead_time):\n",
    "        super(HybridUNet, self).__init__()\n",
    "        self.unet = UNet(in_channels, out_channels)\n",
    "        self.lead_time = lead_time\n",
    "    \n",
    "    def forward(self, x):\n",
    "        predictions = []\n",
    "        current_input = x\n",
    "        \n",
    "        for _ in range(self.lead_time):\n",
    "            # Predict the next time step\n",
    "            next_step = self.unet(current_input)\n",
    "            \n",
    "            # Print shapes before padding\n",
    "            # print('1', current_input.shape)\n",
    "            # print('2', next_step.shape)\n",
    "            \n",
    "            desired_height = 721\n",
    "            desired_width = 1431\n",
    "            desired_channels = 11 \n",
    "\n",
    "            # Calculate padding for height and width\n",
    "            height_padding = (desired_height - next_step.shape[2]) // 2\n",
    "            width_padding = (desired_width - next_step.shape[3]) // 2\n",
    "\n",
    "            # Ensure the padding is correct: add zero padding if dimensions are already correct\n",
    "            height_padding_top = height_padding\n",
    "            height_padding_bottom = desired_height - next_step.shape[2] - height_padding_top\n",
    "\n",
    "            width_padding_left = width_padding\n",
    "            width_padding_right = desired_width - next_step.shape[3] - width_padding_left\n",
    "\n",
    "            # Apply padding\n",
    "            padding = (width_padding_left, width_padding_right, height_padding_top, height_padding_bottom)\n",
    "            next_step = F.pad(next_step, padding)  # Pad to match the desired height and width\n",
    "\n",
    "            # Ensure the shape is (6, 11, 721, 1431)\n",
    "            next_step = next_step.view(-1, desired_channels, desired_height, desired_width)\n",
    "\n",
    "            predictions.append(next_step)\n",
    "            # print('3', next_step.shape)\n",
    "\n",
    "            # Update the input for the next prediction\n",
    "            current_input = torch.cat([current_input[:, 11:, :, :], next_step], dim=1)  # Shift time steps\n",
    "            # print('4', current_input.shape)\n",
    "\n",
    "        # Stack predictions into a single tensor\n",
    "        predictions = torch.stack(predictions, dim=1)  # Shape: (batch_size, lead_time, 8, 721, 1431)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetCDFDataset(Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        self.file_list = file_list \n",
    "        self.means = xr.open_dataset(\"means.nc\").to_array().values\n",
    "        self.stds = xr.open_dataset(\"std.nc\").to_array().values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def normalize(self, ds):\n",
    "        # Convert means and stds to PyTorch tensors\n",
    "        for i, var in enumerate(ds.data_vars):\n",
    "            # Get the data for the current variable (Shape: (lat, lon, time))\n",
    "            data = ds[var]\n",
    "            \n",
    "            # Broadcast means and stds to match the shape of the data (lat, lon, time)\n",
    "            mean = self.means[i]\n",
    "            std = self.stds[i]\n",
    "            \n",
    "            # Normalize the data: (x - mean) / std\n",
    "            normalized_data = (data - mean) / (std + 1e-8)  # Adding a small epsilon to avoid division by zero\n",
    "            \n",
    "            # Update the dataset with the normalized data\n",
    "            ds[var] = normalized_data\n",
    "\n",
    "        return ds\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load a batch (NetCDF file)\n",
    "        file_path = self.file_list[idx]\n",
    "        ds = xr.open_dataset(file_path)\n",
    "        ds = ds.drop_vars([\"tp_mask\", \"sst_mask\", \"pottmp_mask\"])\n",
    "        ds = ds.fillna(-1)\n",
    "        # Apply normalization\n",
    "        ds = self.normalize(ds)\n",
    "        \n",
    "        # Extract data as numpy arrays\n",
    "        data = ds.to_array().values  # Shape: (variables, lat, lon, time)\n",
    "        # print(data.shape)\n",
    "\n",
    "        # correct shape: (variables, lat, lon, time)\n",
    "        assert data.shape[-1] == 6, f\"Expected 6 time steps, but got {data.shape[-1]} in {file_path}\"\n",
    "\n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32)  # Shape: (11, 721, 1431, 6)\n",
    "\n",
    "        # Extract inputs (first 3 time steps)\n",
    "        inputs = data_tensor[..., :3]  # Shape: (11, 721, 1431, 3)\n",
    "        inputs = inputs.reshape(3 * 11, inputs.shape[1], inputs.shape[2])  # Shape: (3*11, 721, 1431)\n",
    "\n",
    "        # Extract targets (last 3 time steps)\n",
    "        targets = data_tensor[..., 3:]  # Shape: (11, 721, 1431, 3)\n",
    "        targets = targets.reshape(3 * 11, targets.shape[1], targets.shape[2])  # Shape: (3*11, 721, 1431)\n",
    "\n",
    "        ds.close()\n",
    "        # print(inputs.shape)\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batches: 360\n",
      "validation batches: 60\n",
      "test batches: 79\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 6\n",
    "in_channels = 3 * 11  # 3 time steps × 11 variables\n",
    "out_channels = 11  # 1 time step × 11 variables\n",
    "lead_time = 3  # Number of time steps to predict\n",
    "height, width = 721, 1431 \n",
    "\n",
    "# Create the model\n",
    "model = HybridUNet(in_channels, out_channels, lead_time)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# Define the folder where batches are stored\n",
    "batch_folder = 'batches/'\n",
    "batch_files = [os.path.join(batch_folder, f) for f in os.listdir(batch_folder) if f.endswith('.nc')]\n",
    "\n",
    "\n",
    "# Define the ratios for splitting\n",
    "train_ratio = 0.723   \n",
    "val_ratio = 0.12    \n",
    "test_ratio = 0.158  \n",
    "\n",
    "# Calculate the split indices\n",
    "num_batches = len(batch_files)\n",
    "train_end_idx = int(num_batches * train_ratio)\n",
    "val_end_idx = int(num_batches * (train_ratio + val_ratio))\n",
    "\n",
    "# Split the list into training, validation, and test sets\n",
    "train_batches = batch_files[:train_end_idx]\n",
    "print('training batches:', len(train_batches))\n",
    "val_batches = batch_files[train_end_idx:val_end_idx]\n",
    "print('validation batches:', len(val_batches))\n",
    "test_batches = batch_files[val_end_idx:]\n",
    "print('test batches:', len(test_batches))\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = NetCDFDataset(train_batches)\n",
    "val_dataset = NetCDFDataset(val_batches)\n",
    "test_dataset = NetCDFDataset(test_batches)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "# Get mask arrays for sst, pottmp and tp\n",
    "ds = xr.open_dataset(\"batches/batch-001-19820101-19820601.nc\")\n",
    "\n",
    "pottmp_mask=ds['pottmp_mask'].values\n",
    "pottmp_mask=torch.tensor(pottmp_mask).to(device)\n",
    "\n",
    "sst_mask=ds['sst_mask'].values\n",
    "sst_mask=torch.tensor(sst_mask).to(device)\n",
    "\n",
    "tp_mask=ds['tp_mask'].values\n",
    "tp_mask=torch.tensor(tp_mask).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(inputs)  # Shape: (batch_size, lead_time, 11, 721, 1431)\n",
    "        predictions = predictions.view(batch_size, lead_time * out_channels, height, width)  # Reshape to match targets\n",
    "\n",
    "        # check for NaN or Inf in predictions or targets\n",
    "        if torch.isnan(predictions).any() or torch.isinf(predictions).any():\n",
    "            print(f\"NaN/Inf detected in predictions at epoch {epoch+1}, batch {batch_idx}\")\n",
    "            \n",
    "        if torch.isnan(targets).any() or torch.isinf(targets).any():\n",
    "            print(f\"NaN/Inf detected in targets at epoch {epoch+1}, batch {batch_idx}\")\n",
    "\n",
    "        \n",
    "        # For other variables, we don't apply the mask.\n",
    "        loss = 0\n",
    "        for i in range(out_channels):\n",
    "            if i == 0:  # Ocean variable\n",
    "                loss += criterion(predictions[:, 0, :, :] * sst_mask, targets[:, 0, :, :] * sst_mask)\n",
    "            elif i == 2:  # pottmp variable\n",
    "                loss += criterion(predictions[:, 2, :, :] * pottmp_mask, targets[:, 2, :, :] * pottmp_mask)\n",
    "            elif i == 10:  # tp variable\n",
    "                loss += 100 * criterion(predictions[:, 10, :, :] * tp_mask, targets[:, 10, :, :] * tp_mask)\n",
    "                # print('prc', 100 * criterion(predictions[:, 10, :, :] * tp_mask, targets[:, 10, :, :] * tp_mask))\n",
    "            else:\n",
    "                loss += criterion(predictions[:, i, :, :], targets[:, i, :, :])\n",
    "                # print(criterion(predictions[:, i, :, :], targets[:, i, :, :]))\n",
    "        \n",
    "        # Check also for NaN/Inf in the loss itself\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            print(f\"NaN/Inf detected in loss at epoch {epoch+1}, batch {batch_idx}\")\n",
    "        \n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    val_loss = 0\n",
    "    num_val_batches = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for val_inputs, val_targets in val_loader:\n",
    "            val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            val_predictions = model(val_inputs)\n",
    "            val_predictions = val_predictions.view(batch_size, lead_time * out_channels, height, width)\n",
    "            \n",
    "            # Compute validation loss (same approach as training loss)\n",
    "            batch_val_loss = 0\n",
    "            for i in range(out_channels):\n",
    "                if i == 0:  # Ocean variable\n",
    "                    batch_val_loss += criterion(val_predictions[:, 0, :, :] * sst_mask, val_targets[:, 0, :, :] * sst_mask)\n",
    "                elif i == 2:  # pottmp variable\n",
    "                    batch_val_loss += criterion(val_predictions[:, 2, :, :] * pottmp_mask, val_targets[:, 2, :, :] * pottmp_mask)\n",
    "                elif i == 10:  # tp variable\n",
    "                    batch_val_loss += 100 * criterion(val_predictions[:, 10, :, :] * tp_mask, val_targets[:, 10, :, :] * tp_mask)\n",
    "                else:\n",
    "                    batch_val_loss += criterion(val_predictions[:, i, :, :], val_targets[:, i, :, :])\n",
    "\n",
    "            val_loss += batch_val_loss.item()\n",
    "            num_val_batches += 1\n",
    "\n",
    "    # Compute average validation loss\n",
    "    avg_val_loss = val_loss / num_val_batches\n",
    "\n",
    "    # Print training and validation loss\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], \"\n",
    "        f\"Train Loss: {loss.item():.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Define where to save the model\n",
    "    model_path = f\"weights/unet_model_epoch_{epoch+1}_train_loss_{loss.item():.2f}_val_loss_{avg_val_loss:.2f}.pth\"\n",
    "\n",
    "    # Save only the model weights (state_dict)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    print(f\"Model weights saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load(\"weights/unet_model_epoch_5_train_loss_5.80_val_loss_6.00.pth\", map_location=device))\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5511274337768555\n"
     ]
    }
   ],
   "source": [
    "# Get a sample batch from the test loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "test_inputs, test_targets = next(iter(test_loader))\n",
    "test_inputs, test_targets = test_inputs.to(device), test_targets.to(device)\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_inputs)  # Shape: (batch_size, lead_time, 11, 721, 1431)\n",
    "\n",
    "# Reshape predictions to match targets\n",
    "predictions = predictions.view(test_targets.shape)  # Ensure they have the same shape\n",
    "loss = 0\n",
    "for i in range(out_channels):\n",
    "    if i == 0:  # Ocean variable\n",
    "        loss += criterion(predictions[:, 0, :, :] * sst_mask, test_targets[:, 0, :, :] * sst_mask)\n",
    "    elif i == 2:  # pottmp variable\n",
    "        loss += criterion(predictions[:, 2, :, :] * pottmp_mask, test_targets[:, 2, :, :] * pottmp_mask)\n",
    "    elif i == 10:  # tp variable\n",
    "        loss += 100 * criterion(predictions[:, 10, :, :] * tp_mask, test_targets[:, 10, :, :] * tp_mask)\n",
    "    else:\n",
    "        loss += criterion(predictions[:, i, :, :], test_targets[:, i, :, :])\n",
    "\n",
    "print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
